{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIdMl2gGdbvl",
        "outputId": "f61bd1dd-200e-4f5a-8218-4807f3f75687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install fuzzywuzzy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-Levenshtein\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB6afROWdo-A",
        "outputId": "5250161e-6f79-463d-d937-07662d1a3da5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.26.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting Levenshtein==0.26.1 (from python-Levenshtein)\n",
            "  Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.26.1->python-Levenshtein)\n",
            "  Downloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading python_Levenshtein-0.26.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
            "Successfully installed Levenshtein-0.26.1 python-Levenshtein-0.26.1 rapidfuzz-3.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np  # For numerical operations\n",
        "import pandas as pd  # For data manipulation\n",
        "from fuzzywuzzy import fuzz  # For fuzzy string matching\n",
        "from fuzzywuzzy import process  # For advanced fuzzy operations\n"
      ],
      "metadata": {
        "id": "1crV2tNod_UD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('tested.csv')  # Replace 'test.csv' with your dataset filename"
      ],
      "metadata": {
        "id": "plmKyyU-eFdR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the dataset\n",
        "print(\"Dataset Preview:\")\n",
        "print(df.head())\n",
        "\n",
        "# Display dataset information\n",
        "print(\"\\nDataset Information:\")\n",
        "print(df.info())\n",
        "\n",
        "# Display summary statistics\n",
        "print(\"\\nDataset Summary Statistics:\")\n",
        "print(df.describe(include='all'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQFmds7reVLC",
        "outputId": "98bc2849-af1f-4f56-e529-68288b9199d0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Preview:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0          892         0       3   \n",
            "1          893         1       3   \n",
            "2          894         0       2   \n",
            "3          895         0       3   \n",
            "4          896         1       3   \n",
            "\n",
            "                                           Name     Sex   Age  SibSp  Parch  \\\n",
            "0                              Kelly, Mr. James    male  34.5      0      0   \n",
            "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
            "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
            "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
            "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
            "\n",
            "    Ticket     Fare Cabin Embarked  \n",
            "0   330911   7.8292   NaN        Q  \n",
            "1   363272   7.0000   NaN        S  \n",
            "2   240276   9.6875   NaN        Q  \n",
            "3   315154   8.6625   NaN        S  \n",
            "4  3101298  12.2875   NaN        S  \n",
            "\n",
            "Dataset Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 418 entries, 0 to 417\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  418 non-null    int64  \n",
            " 1   Survived     418 non-null    int64  \n",
            " 2   Pclass       418 non-null    int64  \n",
            " 3   Name         418 non-null    object \n",
            " 4   Sex          418 non-null    object \n",
            " 5   Age          332 non-null    float64\n",
            " 6   SibSp        418 non-null    int64  \n",
            " 7   Parch        418 non-null    int64  \n",
            " 8   Ticket       418 non-null    object \n",
            " 9   Fare         417 non-null    float64\n",
            " 10  Cabin        91 non-null     object \n",
            " 11  Embarked     418 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 39.3+ KB\n",
            "None\n",
            "\n",
            "Dataset Summary Statistics:\n",
            "        PassengerId    Survived      Pclass              Name   Sex  \\\n",
            "count    418.000000  418.000000  418.000000               418   418   \n",
            "unique          NaN         NaN         NaN               418     2   \n",
            "top             NaN         NaN         NaN  Kelly, Mr. James  male   \n",
            "freq            NaN         NaN         NaN                 1   266   \n",
            "mean    1100.500000    0.363636    2.265550               NaN   NaN   \n",
            "std      120.810458    0.481622    0.841838               NaN   NaN   \n",
            "min      892.000000    0.000000    1.000000               NaN   NaN   \n",
            "25%      996.250000    0.000000    1.000000               NaN   NaN   \n",
            "50%     1100.500000    0.000000    3.000000               NaN   NaN   \n",
            "75%     1204.750000    1.000000    3.000000               NaN   NaN   \n",
            "max     1309.000000    1.000000    3.000000               NaN   NaN   \n",
            "\n",
            "               Age       SibSp       Parch    Ticket        Fare  \\\n",
            "count   332.000000  418.000000  418.000000       418  417.000000   \n",
            "unique         NaN         NaN         NaN       363         NaN   \n",
            "top            NaN         NaN         NaN  PC 17608         NaN   \n",
            "freq           NaN         NaN         NaN         5         NaN   \n",
            "mean     30.272590    0.447368    0.392344       NaN   35.627188   \n",
            "std      14.181209    0.896760    0.981429       NaN   55.907576   \n",
            "min       0.170000    0.000000    0.000000       NaN    0.000000   \n",
            "25%      21.000000    0.000000    0.000000       NaN    7.895800   \n",
            "50%      27.000000    0.000000    0.000000       NaN   14.454200   \n",
            "75%      39.000000    1.000000    0.000000       NaN   31.500000   \n",
            "max      76.000000    8.000000    9.000000       NaN  512.329200   \n",
            "\n",
            "                  Cabin Embarked  \n",
            "count                91      418  \n",
            "unique               76        3  \n",
            "top     B57 B59 B63 B66        S  \n",
            "freq                  3      270  \n",
            "mean                NaN      NaN  \n",
            "std                 NaN      NaN  \n",
            "min                 NaN      NaN  \n",
            "25%                 NaN      NaN  \n",
            "50%                 NaN      NaN  \n",
            "75%                 NaN      NaN  \n",
            "max                 NaN      NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(\"\\nMissing Values in the Dataset:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Display columns with missing values\n",
        "columns_with_na = df.columns[df.isnull().any()]\n",
        "print(\"\\nColumns with Missing Values:\", columns_with_na)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcMEME_oeYG4",
        "outputId": "b700266a-b848-434b-8317-cac13e2fd1f6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing Values in the Dataset:\n",
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age             86\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             1\n",
            "Cabin          327\n",
            "Embarked         0\n",
            "dtype: int64\n",
            "\n",
            "Columns with Missing Values: Index(['Age', 'Fare', 'Cabin'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values\n",
        "df['Age'].fillna(df['Age'].mean(), inplace=True)  # Fill missing 'Age' with mean\n",
        "df['Fare'].fillna(df['Fare'].median(), inplace=True)  # Fill missing 'Fare' with median\n",
        "df.drop('Cabin', axis=1, inplace=True)  # Drop 'Cabin' column due to excessive missing data\n",
        "\n",
        "# Verify no missing values remain\n",
        "print(\"\\nMissing Values After Processing:\")\n",
        "print(df.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv72_Nj2edvZ",
        "outputId": "3396dd0e-c76a-44d5-c39c-e3808fd0363c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing Values After Processing:\n",
            "PassengerId    0\n",
            "Survived       0\n",
            "Pclass         0\n",
            "Name           0\n",
            "Sex            0\n",
            "Age            0\n",
            "SibSp          0\n",
            "Parch          0\n",
            "Ticket         0\n",
            "Fare           0\n",
            "Embarked       0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-91e6e71abc8c>:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Age'].fillna(df['Age'].mean(), inplace=True)  # Fill missing 'Age' with mean\n",
            "<ipython-input-8-91e6e71abc8c>:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Fare'].fillna(df['Fare'].median(), inplace=True)  # Fill missing 'Fare' with median\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display unique values in specific columns\n",
        "print(\"\\nUnique Values in Embarked Column:\")\n",
        "print(df['Embarked'].unique())\n",
        "\n",
        "# Count distribution of a specific column\n",
        "print(\"\\nValue Counts for 'Survived':\")\n",
        "print(df['Survived'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVB8jHzeeg0Z",
        "outputId": "f0ac864f-1c3a-472a-b128-cda4e06650f6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Unique Values in Embarked Column:\n",
            "['Q' 'S' 'C']\n",
            "\n",
            "Value Counts for 'Survived':\n",
            "Survived\n",
            "0    266\n",
            "1    152\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to find potential duplicates using fuzzy matching\n",
        "def find_duplicates(dataframe, column, threshold=80):\n",
        "    duplicates = []\n",
        "    for i, name in enumerate(dataframe[column]):\n",
        "        for j, other_name in enumerate(dataframe[column]):\n",
        "            if i != j:  # Avoid self-comparison\n",
        "                similarity = fuzz.token_sort_ratio(name, other_name)\n",
        "                if similarity >= threshold:\n",
        "                    duplicates.append((name, other_name, similarity))\n",
        "    return duplicates\n",
        "\n",
        "# Apply the function to the 'Name' column\n",
        "potential_duplicates = find_duplicates(df, 'Name', threshold=80)\n",
        "\n",
        "# Display potential duplicates\n",
        "print(\"\\nPotential Duplicates Found:\")\n",
        "for duplicate in potential_duplicates[:10]:  # Show only the first 10 for brevity\n",
        "    print(duplicate)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGUWfTNiekj4",
        "outputId": "9e7226ea-32a2-48b0-fcf1-6d5146d19eee"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Potential Duplicates Found:\n",
            "('Brady, Mr. John Bertram', 'Crafton, Mr. John Bertram', 82)\n",
            "('Davison, Mr. Thomas Henry', 'Conlon, Mr. Thomas Henry', 80)\n",
            "('Kiernan, Mr. John', 'Kennedy, Mr. John', 80)\n",
            "('Kiernan, Mr. John', 'Lingane, Mr. John', 80)\n",
            "('Kennedy, Mr. John', 'Kiernan, Mr. John', 80)\n",
            "('Crafton, Mr. John Bertram', 'Brady, Mr. John Bertram', 82)\n",
            "('Lingane, Mr. John', 'Kiernan, Mr. John', 80)\n",
            "('Dennis, Mr. William', 'Dibden, Mr. William', 82)\n",
            "('Dibden, Mr. William', 'Dennis, Mr. William', 82)\n",
            "('Dibden, Mr. William', 'Gilbert, Mr. William', 80)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deduplicate dataset by retaining unique names\n",
        "unique_names = set()\n",
        "deduplicated_rows = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    name = row['Name']\n",
        "    if name not in unique_names:\n",
        "        deduplicated_rows.append(row)\n",
        "        unique_names.add(name)\n",
        "\n",
        "# Create a new DataFrame with deduplicated rows\n",
        "df_cleaned = pd.DataFrame(deduplicated_rows)\n",
        "\n",
        "# Check the shape of the cleaned dataset\n",
        "print(\"\\nShape of Cleaned Dataset:\")\n",
        "print(df_cleaned.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlwld1hTeqXB",
        "outputId": "18a09dfc-e21d-41b7-ee81-8399ae0f670f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of Cleaned Dataset:\n",
            "(418, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the cleaned dataset\n",
        "df_cleaned.to_csv('cleaned_data.csv', index=False)\n",
        "\n",
        "print(\"\\nCleaned dataset has been saved as 'cleaned_data.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTJchGwFeuca",
        "outputId": "e50e7ab4-3880-458f-efb1-8bfb04cf3ca0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cleaned dataset has been saved as 'cleaned_data.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j68kfd2yexkY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}